export default (function(a,b,c,d,e,f,g,h,i,j,k,l,m,n,o,p,q,r,s,t,u,v,w,x,y,z,A,B,C,D,E,F,G,H,I,J,K,L,M,N,O,P){return {data:{home:{_path:"\u002Fhome\u002Fhero",_dir:s,_draft:a,_partial:a,_locale:b,_empty:o,title:"Hero",description:b,section:"hero",text:"A non-linear audio streaming framework for real-time radiophonic experiences and live music.",body:{type:f,children:[],toc:{title:b,searchDepth:c,depth:c,links:[]}},_type:g,_id:"content:1.home:hero.md",_source:h,_file:"1.home\u002Fhero.md",_extension:i},general:{_path:"\u002Fhome\u002Fgeneral",_dir:s,_draft:a,_partial:a,_locale:b,_empty:a,title:t,description:u,section:"general",heading:t,img:{src:"\u002Fimg\u002Fspiral.svg",alt:"Gencaster Spiral"},color:"green",body:{type:f,children:[{type:d,tag:j,props:{},children:[{type:e,value:u}]},{type:d,tag:j,props:{},children:[{type:e,value:"This new way of streaming audio allows the introduction of new formats generated by user preference or interaction (e.g. a weather forecast derived from GPS location). Due to the low latency of WebRTC technology, we can achieve new ways of storytelling and story distribution that are not limited to the spoken context, but can also be used for new musical compositions."}]},{type:d,tag:j,props:{},children:[{type:e,value:"Our player (running on WebRTC) allows to embed this audio stream in an app or simply on a website, making the barrier for the user to listen to the stream very low."}]}],toc:{title:b,searchDepth:c,depth:c,links:[]}},_type:g,_id:"content:1.home:general.md",_source:h,_file:"1.home\u002Fgeneral.md",_extension:i},features:[{_path:"\u002Fhome\u002Ffeatures\u002Fgenerative-storytelling",_dir:n,_draft:a,_partial:a,_locale:b,_empty:a,title:v,description:w,section:n,heading:v,body:{type:f,children:[{type:d,tag:j,props:{},children:[{type:e,value:w}]}],toc:{title:b,searchDepth:c,depth:c,links:[]}},_type:g,_id:"content:1.home:features:1.generative-storytelling.md",_source:h,_file:"1.home\u002Ffeatures\u002F1.generative-storytelling.md",_extension:i},{_path:"\u002Fhome\u002Ffeatures\u002Flow-latency",_dir:n,_draft:a,_partial:a,_locale:b,_empty:a,title:x,description:y,section:n,heading:x,body:{type:f,children:[{type:d,tag:j,props:{},children:[{type:e,value:y}]}],toc:{title:b,searchDepth:c,depth:c,links:[]}},_type:g,_id:"content:1.home:features:2.low-latency.md",_source:h,_file:"1.home\u002Ffeatures\u002F2.low-latency.md",_extension:i},{_path:"\u002Fhome\u002Ffeatures\u002Fuser-interaction",_dir:n,_draft:a,_partial:a,_locale:b,_empty:a,title:z,description:A,section:n,heading:z,body:{type:f,children:[{type:d,tag:j,props:{},children:[{type:e,value:A}]}],toc:{title:b,searchDepth:c,depth:c,links:[]}},_type:g,_id:"content:1.home:features:3.user-interaction.md",_source:h,_file:"1.home\u002Ffeatures\u002F3.user-interaction.md",_extension:i},{_path:"\u002Fhome\u002Ffeatures\u002Fparallel-streams",_dir:n,_draft:a,_partial:a,_locale:b,_empty:a,title:B,description:C,section:n,heading:B,body:{type:f,children:[{type:d,tag:j,props:{},children:[{type:e,value:C}]}],toc:{title:b,searchDepth:c,depth:c,links:[]}},_type:g,_id:"content:1.home:features:4.parallel-streams.md",_source:h,_file:"1.home\u002Ffeatures\u002F4.parallel-streams.md",_extension:i}],editor_text:{_path:"\u002Fhome\u002Feditor\u002Feditor",_dir:p,_draft:a,_partial:a,_locale:b,_empty:a,title:"Editor",description:"The editor is the control interface for gencaster. It allows anyone to create, manage and update their own dynamic audio experiences. The graph-based layout represents the logical connections between the different parts of the audio composition. Each node in turn contains the information needed to create the individual scenes. These can range from uploaded audio recordings to completely real-time generated content, allowing for a wide range of formats.\nWe have focused on creating an editor that can be used without any specific coding experience. However, for those who want to take their creations to the next level, the node cells can be extended with code in different languages to increase complexity or add dynamic content, such as generated text, generative background music or special logic.",body:{type:f,children:[{type:d,tag:j,props:{},children:[{type:e,value:"The editor is the control interface for gencaster. It allows anyone to create, manage and update their own dynamic audio experiences. The graph-based layout represents the logical connections between the different parts of the audio composition. Each node in turn contains the information needed to create the individual scenes. These can range from uploaded audio recordings to completely real-time generated content, allowing for a wide range of formats."},{type:d,tag:"br",props:{},children:[]},{type:e,value:"\nWe have focused on creating an editor that can be used without any specific coding experience. However, for those who want to take their creations to the next level, the node cells can be extended with code in different languages to increase complexity or add dynamic content, such as generated text, generative background music or special logic."}]}],toc:{title:b,searchDepth:c,depth:c,links:[]}},_type:g,_id:"content:1.home:editor:editor.md",_source:h,_file:"1.home\u002Feditor\u002Feditor.md",_extension:i},editor_tabs:[{_path:"\u002Fhome\u002Feditor\u002Ftabs\u002Fpersonalized-podcast",_dir:r,_draft:a,_partial:a,_locale:b,_empty:o,title:D,description:b,section:p,img:{src:"\u002Fimg\u002Fgraphs\u002Fgraph-podcast.svg",alt:D},body:{type:f,children:[],toc:{title:b,searchDepth:c,depth:c,links:[]}},_type:g,_id:"content:1.home:editor:tabs:1.personalized-podcast.md",_source:h,_file:"1.home\u002Feditor\u002Ftabs\u002F1.personalized-podcast.md",_extension:i},{_path:"\u002Fhome\u002Feditor\u002Ftabs\u002Flocation-aware-soundwalk",_dir:r,_draft:a,_partial:a,_locale:b,_empty:o,title:E,description:b,section:p,img:{src:"\u002Fimg\u002Fgraphs\u002Fgraph-audiowalk.svg",alt:E},body:{type:f,children:[],toc:{title:b,searchDepth:c,depth:c,links:[]}},_type:g,_id:"content:1.home:editor:tabs:2.location-aware-soundwalk.md",_source:h,_file:"1.home\u002Feditor\u002Ftabs\u002F2.location-aware-soundwalk.md",_extension:i},{_path:"\u002Fhome\u002Feditor\u002Ftabs\u002Fradio-art",_dir:r,_draft:a,_partial:a,_locale:b,_empty:o,title:F,description:b,section:p,img:{src:"\u002Fimg\u002Fgraphs\u002Fgraph-radio-art.svg",alt:F},body:{type:f,children:[],toc:{title:b,searchDepth:c,depth:c,links:[]}},_type:g,_id:"content:1.home:editor:tabs:3.radio-art.md",_source:h,_file:"1.home\u002Feditor\u002Ftabs\u002F3.radio-art.md",_extension:i}],support:[{_path:"\u002Fgeneral\u002Fsupport\u002Fmiz",_dir:G,_draft:a,_partial:a,_locale:b,_empty:o,title:"Miz",description:b,section:G,img_src:"\u002Fimg\u002Fsupport\u002Fmiz_black_logo.svg",img_alt:"Medieninnovationszentrum Babelsberg",text:"We are very fortunate to have received the innovation funding by MIZ Babelsberg. They helped support the alpha development of Gencaster 2022 - 2023.",body:{type:f,children:[],toc:{title:b,searchDepth:c,depth:c,links:[]}},_type:g,_id:"content:general:support:1.miz.md",_source:h,_file:"general\u002Fsupport\u002F1.miz.md",_extension:i}],news:[{_path:"\u002Fnews\u002Fzkm-next_generation",_dir:H,_draft:a,_partial:a,_locale:b,_empty:a,title:I,description:"In the summer of 2022, Dennis was invited to present Gencaster at the Meeting of the university studios for electronic music: Next_generation 9.0.",subtitle:J,teaser_img:{src:"\u002Fimg\u002Fnews\u002Fzkm-next-generation\u002Flanding.jpg",alt:I},date:"2022-06-25",categories:q,tags:[q,K],body:{type:f,children:[{type:d,tag:j,props:{},children:[{type:e,value:"In the summer of 2022, Dennis was invited to present Gencaster at the Meeting of the university studios for electronic music: "},{type:d,tag:"a",props:{href:"https:\u002F\u002Fzkm.de\u002Fde\u002Fveranstaltung\u002F2022\u002F06\u002Fnextgeneration-90-0",rel:["nofollow"]},children:[{type:e,value:"Next_generation 9.0"}]},{type:e,value:"."}]},{type:d,tag:j,props:{},children:[{type:d,tag:k,props:{":class":l,alt:m,src:"\u002Fimg\u002Fnews\u002Fzkm-next-generation\u002F1.png"},children:[]},{type:d,tag:k,props:{":class":l,alt:m,src:"\u002Fimg\u002Fnews\u002Fzkm-next-generation\u002F2.png"},children:[]},{type:d,tag:k,props:{":class":l,alt:m,src:"\u002Fimg\u002Fnews\u002Fzkm-next-generation\u002F3.png"},children:[]},{type:d,tag:k,props:{":class":l,alt:m,src:"\u002Fimg\u002Fnews\u002Fzkm-next-generation\u002F4.png"},children:[]},{type:d,tag:k,props:{":class":l,alt:m,src:"\u002Fimg\u002Fnews\u002Fzkm-next-generation\u002F5.png"},children:[]}]}],toc:{title:b,searchDepth:c,depth:c,links:[]}},_type:g,_id:"content:3.news:zkm-next_generation.md",_source:h,_file:"3.news\u002Fzkm-next_generation.md",_extension:i},{_path:"\u002Fnews\u002Fmiz-interim",_dir:H,_draft:a,_partial:a,_locale:b,_empty:a,title:L,description:M,subtitle:J,teaser_img:{src:"\u002Fimg\u002Fnews\u002Fmiz-interim\u002Flanding.jpg",alt:L},date:"2022-11-23",categories:q,tags:[q,K],body:{type:f,children:[{type:d,tag:j,props:{},children:[{type:e,value:M}]},{type:d,tag:j,props:{},children:[{type:d,tag:k,props:{":class":l,alt:m,src:"\u002Fimg\u002Fnews\u002Fmiz-interim\u002F1.png"},children:[]},{type:d,tag:k,props:{":class":l,alt:m,src:"\u002Fimg\u002Fnews\u002Fmiz-interim\u002F2.png"},children:[]},{type:d,tag:k,props:{":class":l,alt:m,src:"\u002Fimg\u002Fnews\u002Fmiz-interim\u002F3.png"},children:[]},{type:d,tag:k,props:{":class":l,alt:m,src:"\u002Fimg\u002Fnews\u002Fmiz-interim\u002F4.png"},children:[]}]},{type:d,tag:"h2",props:{id:N},children:[{type:e,value:O}]},{type:d,tag:"iframe",props:{style:"aspect-ratio: 16 \u002F 9;",width:P,height:P,src:"https:\u002F\u002Fwww.youtube-nocookie.com\u002Fembed\u002FCZqxDaAjsjk?start=614",title:"YouTube video player",frameBorder:"0",allow:"accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture; web-share",allowFullScreen:o},children:[]}],toc:{title:b,searchDepth:c,depth:c,links:[{id:N,depth:c,text:O}]}},_type:g,_id:"content:3.news:miz-interim.md",_source:h,_file:"3.news\u002Fmiz-interim.md",_extension:i}]},prerenderedAt:1683724242075}}(false,"",2,"element","text","root","markdown","content","md","p","img","border","slide","features",true,"editor","presentation","tabs","home","General","Gencaster is a platform for building audio streaming experiences with dynamic and generative content. This allows for a unique stream per user instead of delivering the same synchronised stream to everyone (traditional radio broadcasting) or relying on on-demand interaction (current streaming\u002Fpodcast platforms).","Generative Storytelling","Having the possibility to access properties from the user allows to create new ways of storytelling. E.g. the current date, location or movement can be used to generate a new path of a story or audio composition. Theoretically we can plug any other content generation system into the audio stream.","Low Latency","Using WebRTC allows us to stream audio with a latency of around 100ms. Traditional audio streams in the internet mostly have a latency of around 20 seconds, making real time adaption or generation impossible.","User Interaction","Due to the low latency we can use the feedback of the listener immediately via interactions. These interactions can be based on the GPS location of the user, allowing not only for dynamic content but also for content that is suited for the listener. This interaction is not limited to numerical data but can also be the microphone of the listener, making it possible to analyze and modify the environmental sounds of the user.","Parallel Streams","Gencaster is built in such a way that it can serve multiple users their own stream or that multiple users can share a stream. Gencaster manages multiple streams and their user assignments and a stream can be assigned to an user in less than 1 second.","Personalized Podcast","Location-Aware Soundwalk","Radio Art","support","news","Next_generation 9.0 @ ZKM",null,"demo","Interim presentation @ MIZ Babelsberg","We were invited at the MIZ to present our current state of development during the Role Model Session #11. Some slides from the presentation:","full-presentation","Full Presentation","100%"))