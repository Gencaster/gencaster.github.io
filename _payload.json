[{"data":1,"prerenderedAt":259},["Reactive",2],{"home":3,"general":23,"features":55,"editor_text":113,"editor_tabs":128,"support":163,"news":177},{"_path":4,"_dir":5,"_draft":6,"_partial":6,"_locale":7,"_empty":8,"title":9,"description":7,"section":10,"text":11,"body":12,"_type":18,"_id":19,"_source":20,"_file":21,"_extension":22},"/home/hero","home",false,"",true,"Hero","hero","A non-linear audio streaming framework for real-time radiophonic experiences and live music.",{"type":13,"children":14,"toc":15},"root",[],{"title":7,"searchDepth":16,"depth":16,"links":17},2,[],"markdown","content:1.home:hero.md","content","1.home/hero.md","md",{"_path":24,"_dir":5,"_draft":6,"_partial":6,"_locale":7,"_empty":6,"title":25,"description":26,"section":27,"heading":25,"img":28,"color":31,"body":32,"_type":18,"_id":53,"_source":20,"_file":54,"_extension":22},"/home/general","General","Gencaster is a platform for building audio streaming experiences with dynamic and generative content. This allows for a unique stream per user instead of delivering the same synchronised stream to everyone (traditional radio broadcasting) or relying on on-demand interaction (current streaming/podcast platforms).","general",{"src":29,"alt":30},"/img/spiral.svg","Gencaster Spiral","green",{"type":13,"children":33,"toc":51},[34,41,46],{"type":35,"tag":36,"props":37,"children":38},"element","p",{},[39],{"type":40,"value":26},"text",{"type":35,"tag":36,"props":42,"children":43},{},[44],{"type":40,"value":45},"This new way of streaming audio allows the introduction of new formats generated by user preference or interaction (e.g. a weather forecast derived from GPS location). Due to the low latency of WebRTC technology, we can achieve new ways of storytelling and story distribution that are not limited to the spoken context, but can also be used for new musical compositions.",{"type":35,"tag":36,"props":47,"children":48},{},[49],{"type":40,"value":50},"Our player (running on WebRTC) allows to embed this audio stream in an app or simply on a website, making the barrier for the user to listen to the stream very low.",{"title":7,"searchDepth":16,"depth":16,"links":52},[],"content:1.home:general.md","1.home/general.md",[56,71,85,99],{"_path":57,"_dir":58,"_draft":6,"_partial":6,"_locale":7,"_empty":6,"title":59,"description":60,"section":58,"heading":59,"body":61,"_type":18,"_id":69,"_source":20,"_file":70,"_extension":22},"/home/features/generative-storytelling","features","Generative Storytelling","Having the possibility to access properties from the user allows to create new ways of storytelling. E.g. the current date, location or movement can be used to generate a new path of a story or audio composition. Theoretically we can plug any other content generation system into the audio stream.",{"type":13,"children":62,"toc":67},[63],{"type":35,"tag":36,"props":64,"children":65},{},[66],{"type":40,"value":60},{"title":7,"searchDepth":16,"depth":16,"links":68},[],"content:1.home:features:1.generative-storytelling.md","1.home/features/1.generative-storytelling.md",{"_path":72,"_dir":58,"_draft":6,"_partial":6,"_locale":7,"_empty":6,"title":73,"description":74,"section":58,"heading":73,"body":75,"_type":18,"_id":83,"_source":20,"_file":84,"_extension":22},"/home/features/low-latency","Low Latency","Using WebRTC allows us to stream audio with a latency of around 100ms. Traditional audio streams in the internet mostly have a latency of around 20 seconds, making real time adaption or generation impossible.",{"type":13,"children":76,"toc":81},[77],{"type":35,"tag":36,"props":78,"children":79},{},[80],{"type":40,"value":74},{"title":7,"searchDepth":16,"depth":16,"links":82},[],"content:1.home:features:2.low-latency.md","1.home/features/2.low-latency.md",{"_path":86,"_dir":58,"_draft":6,"_partial":6,"_locale":7,"_empty":6,"title":87,"description":88,"section":58,"heading":87,"body":89,"_type":18,"_id":97,"_source":20,"_file":98,"_extension":22},"/home/features/user-interaction","User Interaction","Due to the low latency we can use the feedback of the listener immediately via interactions. These interactions can be based on the GPS location of the user, allowing not only for dynamic content but also for content that is suited for the listener. This interaction is not limited to numerical data but can also be the microphone of the listener, making it possible to analyze and modify the environmental sounds of the user.",{"type":13,"children":90,"toc":95},[91],{"type":35,"tag":36,"props":92,"children":93},{},[94],{"type":40,"value":88},{"title":7,"searchDepth":16,"depth":16,"links":96},[],"content:1.home:features:3.user-interaction.md","1.home/features/3.user-interaction.md",{"_path":100,"_dir":58,"_draft":6,"_partial":6,"_locale":7,"_empty":6,"title":101,"description":102,"section":58,"heading":101,"body":103,"_type":18,"_id":111,"_source":20,"_file":112,"_extension":22},"/home/features/parallel-streams","Parallel Streams","Gencaster is built in such a way that it can serve multiple users their own stream or that multiple users can share a stream. Gencaster manages multiple streams and their user assignments and a stream can be assigned to an user in less than 1 second.",{"type":13,"children":104,"toc":109},[105],{"type":35,"tag":36,"props":106,"children":107},{},[108],{"type":40,"value":102},{"title":7,"searchDepth":16,"depth":16,"links":110},[],"content:1.home:features:4.parallel-streams.md","1.home/features/4.parallel-streams.md",{"_path":114,"_dir":115,"_draft":6,"_partial":6,"_locale":7,"_empty":6,"title":116,"description":117,"body":118,"_type":18,"_id":126,"_source":20,"_file":127,"_extension":22},"/home/editor/editor","editor","Editor","The editor is the control interface for gencaster. It allows anyone to create, manage and update their own dynamic audio experiences. The graph-based layout represents the logical connections between the different parts of the audio composition. Each node in turn contains the information needed to create the individual scenes. These can range from uploaded audio recordings to completely real-time generated content, allowing for a wide range of formats.\nWe have focused on creating an editor that can be used without any specific coding experience. However, for those who want to take their creations to the next level, the node cells can be extended with code in different languages to increase complexity or add dynamic content, such as generated text, generative background music or special logic.",{"type":13,"children":119,"toc":124},[120],{"type":35,"tag":36,"props":121,"children":122},{},[123],{"type":40,"value":117},{"title":7,"searchDepth":16,"depth":16,"links":125},[],"content:1.home:editor:editor.md","1.home/editor/editor.md",[129,141,152],{"_path":130,"_dir":131,"_draft":6,"_partial":6,"_locale":7,"_empty":8,"title":132,"description":7,"section":115,"img":133,"body":135,"_type":18,"_id":139,"_source":20,"_file":140,"_extension":22},"/home/editor/tabs/personalized-podcast","tabs","Personalized Podcast",{"src":134,"alt":132},"/img/graphs/graph-podcast.svg",{"type":13,"children":136,"toc":137},[],{"title":7,"searchDepth":16,"depth":16,"links":138},[],"content:1.home:editor:tabs:1.personalized-podcast.md","1.home/editor/tabs/1.personalized-podcast.md",{"_path":142,"_dir":131,"_draft":6,"_partial":6,"_locale":7,"_empty":8,"title":143,"description":7,"section":115,"img":144,"body":146,"_type":18,"_id":150,"_source":20,"_file":151,"_extension":22},"/home/editor/tabs/location-aware-soundwalk","Location-Aware Soundwalk",{"src":145,"alt":143},"/img/graphs/graph-audiowalk.svg",{"type":13,"children":147,"toc":148},[],{"title":7,"searchDepth":16,"depth":16,"links":149},[],"content:1.home:editor:tabs:2.location-aware-soundwalk.md","1.home/editor/tabs/2.location-aware-soundwalk.md",{"_path":153,"_dir":131,"_draft":6,"_partial":6,"_locale":7,"_empty":8,"title":154,"description":7,"section":115,"img":155,"body":157,"_type":18,"_id":161,"_source":20,"_file":162,"_extension":22},"/home/editor/tabs/radio-art","Radio Art",{"src":156,"alt":154},"/img/graphs/graph-radio-art.svg",{"type":13,"children":158,"toc":159},[],{"title":7,"searchDepth":16,"depth":16,"links":160},[],"content:1.home:editor:tabs:3.radio-art.md","1.home/editor/tabs/3.radio-art.md",[164],{"_path":165,"_dir":166,"_draft":6,"_partial":6,"_locale":7,"_empty":8,"title":167,"description":7,"section":166,"img_src":168,"img_alt":169,"text":170,"body":171,"_type":18,"_id":175,"_source":20,"_file":176,"_extension":22},"/general/support/miz","support","Miz","/img/support/miz_black_logo.svg","Medieninnovationszentrum Babelsberg","We are very fortunate to have received the innovation funding by MIZ Babelsberg. They helped support the alpha development of Gencaster 2022 - 2023.",{"type":13,"children":172,"toc":173},[],{"title":7,"searchDepth":16,"depth":16,"links":174},[],"content:general:support:1.miz.md","general/support/1.miz.md",[178,209],{"_path":179,"_dir":180,"_draft":6,"_partial":6,"_locale":7,"_empty":6,"title":181,"description":182,"subtitle":183,"teaser_img":184,"date":187,"categories":188,"tags":189,"body":191,"_type":18,"_id":207,"_source":20,"_file":208,"_extension":22},"/news/live-coding-gencaster","news","Live coding gencaster","Dennis Scheiba held a concert where he was sending generative sound layers through the phones of the audience.",null,{"src":185,"alt":186},"/img/news/live-coding-gencaster/live-coding-gencaster.jpg","Dennis Scheiba holding a collaborative concert with gencaster","2023-05-06","concert",[188,190],"demo",{"type":13,"children":192,"toc":205},[193,197],{"type":35,"tag":36,"props":194,"children":195},{},[196],{"type":40,"value":182},{"type":35,"tag":36,"props":198,"children":199},{},[200],{"type":35,"tag":201,"props":202,"children":204},"img",{"alt":203,"src":185},"slide",[],{"title":7,"searchDepth":16,"depth":16,"links":206},[],"content:3.news:live-coding-gencaster.md","3.news/live-coding-gencaster.md",{"_path":210,"_dir":180,"_draft":6,"_partial":6,"_locale":7,"_empty":6,"title":211,"description":212,"subtitle":183,"teaser_img":213,"date":216,"categories":188,"tags":217,"body":218,"_type":18,"_id":257,"_source":20,"_file":258,"_extension":22},"/news/ambiente-sonoro","Ambiente Sonoro I - Paul Müller Reyes","At the Kunst Uni Graz, Paul Müller Reyes used gencaster to distribute his composition « Ambiente Sonoro I » with additional effects to the mobile phones of the audience on place and online.",{"src":214,"alt":215},"/img/news/ambiente-sonoro/ambiente-sonoro-color.jpg","Title of ambiente sonoro with a background texture","2023-01-28",[188,190],{"type":13,"children":219,"toc":253},[220,224,229,239,246],{"type":35,"tag":36,"props":221,"children":222},{},[223],{"type":40,"value":212},{"type":35,"tag":36,"props":225,"children":226},{},[227],{"type":40,"value":228},"Gencaster recieved the output of the mixer, added additional processing and then sent it to the listeners.",{"type":35,"tag":230,"props":231,"children":238},"iframe",{"style":232,"width":233,"height":233,"src":234,"title":235,"frameBorder":236,"allow":237,"allowFullScreen":8},"aspect-ratio: 16 / 9;","100%","https://www.youtube-nocookie.com/embed/Y9nrXqGo990","YouTube video player","0","accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture; web-share",[],{"type":35,"tag":240,"props":241,"children":243},"h3",{"id":242},"poster-shown-at-the-event",[244],{"type":40,"value":245},"Poster shown at the event",{"type":35,"tag":36,"props":247,"children":248},{},[249],{"type":35,"tag":201,"props":250,"children":252},{"alt":203,"src":251},"/img/news/ambiente-sonoro/ambiente-sonoro-poster.jpg",[],{"title":7,"searchDepth":16,"depth":16,"links":254},[255],{"id":242,"depth":256,"text":245},3,"content:3.news:ambiente-sonoro.md","3.news/ambiente-sonoro.md",1684767360020]